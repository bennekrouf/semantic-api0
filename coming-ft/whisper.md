Set up a Rust backend that integrates Whisper for speech-to-text transcription. The backend should receive an audio file from a Next.js frontend, process it using Whisper for transcription, and then apply context adaptation (e.g., intent recognition or domain-specific formatting). After adaptation, the backend should identify the correct API to call based on the processed text and return a structured JSON response to the frontend. The Next.js app should capture user audio, send it to the backend, and display the final API results after execution. Optimize for low-latency processing and efficient API selection.
